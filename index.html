<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" href="assets/favicon.ico" type="image/x-icon">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="preload" href="assets/fonts/xxx.woff" as="font" type="font/woff" crossorigin>

  <title>Yifei Wang</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="main.css">
  <link rel="canonical" href="yifeiwang.me">
  <link rel="preload" href="assets/font/Mukta-Light.ttf" as="font" type="font/woff" crossorigin>
  <link rel="preload" href="assets/font/Mukta-Medium.ttf" as="font" type="font/woff" crossorigin>

  <!-- <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Mukta:wght@300;400&display=swap" rel="stylesheet"> -->
  <!-- <style>
    a { color: #FF0000; } /* CSS link color */
  </style> -->
</head>

<body data-new-gr-c-s-check-loaded="14.1029.0" data-gr-ext-installed="">



  <main class="page-content" aria-label="Content">
    <div class="wrapper">

      <article class="post">
        <div class="post-content">
          <img src="assets/avatar.JPG" class="profile-picture">

          <p> This is Yifei Wang (Áéã‰∏ÄÈ£û)'s homepage. I am generally interested in developing theoretical understandings and principled methods for machine learning. My works mainly lie in the areas of
             <strong>unsupervised learning</strong> (representation & generation), <strong>robust learning</strong> (adversarial & OOD robustness), and <strong>graph learning</strong> (GNN & Transformer). 
            </p>

             <p>
             I got my PhD (Applied Mathematics) in 2023 from <a href="https://www.pku.edu.cn">Peking University (PKU)</a>, advised by <a href="https://yisenwang.github.io/">Yisen Wang</a>, <a href="https://www.math.pku.edu.cn/jsdw/js_20180628175159671361/y_20180628175159671361/69984.htm">Jiansheng Yang</a>, and <a href="https://zhouchenlin.github.io/">Zhouchen Lin</a>. Prior to that, I received a BS in mathematics and a BA in philosophy from PKU. 
             I am a recipant of <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Best ML Paper Award</a> of ECML-PKDD 2021 and <a href="https://advml-workshop.github.io/icml2021/">Silver Best Paper Award</a> of ICML 2021 AdvML workshop. 
          </p>

          <p>
           Some links: <a href="mailto:yifei_wang@pku.edu.cn">Email</a> /
            <a href="assets/yifei-wang-pku-cv.pdf"><span>CV</span></a> /
            <a href="https://github.com/yifeiwang77">Github</i></span></a> / 
            <a href="https://twitter.com/pkuwangyifei">Twitter</a> /
            <a href="https://scholar.google.com/citations?hl=en&user=-CLy6YsAAAAJ"><span>Google Scholar</span></a>
          </p>


        </div>
      </article>
      <p>
        <strong style="color:#0F9D58">
          If you have questions regarding my work or have some interesting thoughts to discuss, just drop me an email. </strong>
      </p>

    </div>

    

    <div class="wrapper">
      <!-- <article class="post"> -->
        <header class="post-header">
          <h1 class="post-title">News </h1>
        </header>
        <article class="post">

          <ul>
            <li>2023.07. I defended my dissertation and became officially a PhD! Look forward to the new journey ahead.
            <!-- <li>2023.05. I attended ICLR 2023 held in Kigali, Rwanda, as my first ever conference. Met many new friends there. An absolute enjoyment.</li> -->
            <li>üåü Two SSL theory papers were accepted by <strong>ICML 2023</strong>, which analyze the roles of <a href="https://arxiv.org/pdf/2306.04272">multi-modal supervision (e.g., image-text pairs in CLIP)</a> and <a href="https://arxiv.org/pdf/2306.04160">weak supervision (e.g., noisy labels)</a> in self-supervised learning
            <li> One paper on <a href="https://arxiv.org/pdf/2303.14460.pdf">fair AT</a> was accepted by CVPR 2023</li> 
            <li>One paper on <a href="https://zhouchenlin.github.io/Publications/2023-TIP-Denoising.pdf">equilibrium-based image denoising</a> was accepted by IEEE Transaction on Image Processing (TIP)</li>
            <li>üåü Five papers I like very much on <a href="https://openreview.net/pdf?id=VBTJqqWjxMv">Contrastive learning dynamics</a>, <a href="https://openreview.net/pdf?id=cIbjyd2Vcy">Non-contrastive learning dynamics</a>,  <a href="https://openreview.net/pdf?id=0qmwFNJyxCL">DynACL (SOTA adv robustness in SSL)</a>, <a href="https://openreview.net/pdf?id=SM7XkJouWHm">ContraNorm (CL for GNN & Transformer oversmoothing)</a>, and <a href="https://openreview.net/pdf?id=j3cUWIMsFBN">Unbiased sampling for GNN</a> were accepted by <strong>ICLR 2023</strong>!</li>
            <li> Two workshop papers were also accepted by ICLR 2023: one on <a href="https://openreview.net/pdf?id=Noj1Fydegod">SSL-based backdoor defense</a> ‚Üí <a href="https://iclr23-bands.github.io/">ICLR'23 BANDS</a> & one exploring <a href="https://openreview.net/pdf?id=T-NiH_wB1O">what CL learns beyond class-wise features</a> ‚Üí  <a href="">ICLR'23 ME-Fomo</a></li>
            <li>One paper on <a href="">AT-and-IRM connection</a> <strong style="color:#0F9D58">(Oral)</strong> was accepted by AAAI 2023 </li>
            <li>üåü Three papers on <a href="https://arxiv.org/pdf/2210.08344">MAE theory</a> <strong style="color:#0F9D58">(Spotlight)</strong>, <a href="https://arxiv.org/pdf/2210.06807">Structured AT</a> <strong style="color:#0F9D58">(Spotlight)</strong>, and <a href="https://arxiv.org/pdf/2210.07540.pdf">AT recipe for ViTs</a> <strong style="color:#0F9D58">(Spotlight)</strong> were accepted by <strong>NeurIPS 2022</strong>
            <li>Two papers on  <a href="https://sslneurips22.github.io/paper_pdfs/paper_68.pdf">CL identifiability</a> <strong style="color:#0F9D58">(Oral)</strong> & <a href="https://sslneurips22.github.io/paper_pdfs/paper_64.pdf">EBM-based SSL</a> were accepted by NeurIPS 2022 SSL workshop
            <!-- <li>Two papers on <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf">nonlinear graph diffusion</a> and <a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf">concentrated spectral graph filters</a> were accepted by ICML 2022 </li>
            <li>Two papers on <a href="http://arxiv.org/pdf/2203.13457">Contrastive Learning theory</a> and <a href="http://arxiv.org/pdf/2203.13455">AT as EBM training</a> were accepted by ICLR 2022 </li>
            <li>Two papers on <a href="https://arxiv.org/pdf/2110.15348">briding invariant & equivariant SSL</a> and <a href="https://arxiv.org/pdf/2007.01356">GCN's continuous diffusion</a> were accepted by NeurIPS 2021 </li>
            <li>One paper on <a href="https://openreview.net/pdf?id=U0TCTe68s41">AT as EBM training</a> was accepted by ICML 2021 AdvML workshop and won <strong style="color:#0F9D58">Silver Best Paper Award</strong>! </li>
            <li>One paper on <a href="https://arxiv.org/pdf/2107.00352">reparameterized MCMC</a> was accepted by ECML-PKDD 2021 and won <strong style="color:#0F9D58">Best ML Paper Award (1/685)</strong>!</li> -->
          </ul>
        </article>
    </div>

    <div class="wrapper">
      <article class="post">
        <header class="post-header">
          <h1 class="post-title" id="Publications">Publications <span style="font-size:small;letter-spacing:0.00px;">(* marks equal contribution)</a></span> </h1>
          <!-- <span class="footnote">* marks equal contribution</span> -->
        </header> 
      </article>
    <!-- Tab links -->
    <div class="tab">
      <button class="tablinks" disabled><strong>Gallery:</strong></button>
      <button class="tablinks" onclick="openCity(event, 'Selected')"   id="defaultOpen">üåü Selected</button>
      <button class="tablinks" onclick="openCity(event, 'All')"  id="defaultOpen">üìö All</button>
      <button class="tablinks" onclick="openCity(event, 'Unsupervised')">üéÇ Unsupervised Learning</button>
      <button class="tablinks" onclick="openCity(event, 'Adversarial')">üî® Robust Learning</button>
      <button class="tablinks" onclick="openCity(event, 'Graph')">üåê Graph Learning</button>
    </div>

    <!-- Tab content -->
    <div id="Selected" class="tabcontent">
      <!-- <h3>Selected</h3> -->
      <ul class="publications">

        <li class="article">
          <span class="title">
            On the Generalization of Multi-modal Contrastive Learning 
          </span>
          <span class="authors">Qi Zhang*, <strong>Yifei Wang*</strong>, Yisen Wang </span>
          <span class="journal-info">ICML 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2306.04272">PDF</a> | 
            <a href="https://github.com/PKU-ML/CLIP-Help-SimCLR">Code</a>
          </span>
          </li>
          
        <li class="article">
          <span class="title">
            A Message Passing Perspective on Learning Dynamics of Contrastive Learning
          </span>
          <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, <u>Tianqi Du</u>, Jiansheng Yang, Zhouchen Lin, Yisen Wang </span>
          <span class="journal-info">ICLR 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://openreview.net/pdf?id=VBTJqqWjxMv">PDF</a> |
            <a href="https://github.com/PKU-ML/Message-Passing-Contrastive-Learning">Code</a> |
            <a href="assets/slides/ICLR23_Message_Passing.pdf">Slides</a> |
            <a href="https://mp.weixin.qq.com/s/e18pZfee7ffwAHMUBZ_OEg">Blog</a>
          </span>
      </li>

      <li class="article">
        <span class="title">
          Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism
        </span>
        <span class="authors"><u>Zhijian Zhuo*</u>, <strong>Yifei Wang*</strong>, Jinwen Ma, Yisen Wang </span>
        <span class="journal-info">ICLR 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://openreview.net/pdf?id=cIbjyd2Vcy">PDF</a> | 
          <a href="https://github.com/PKU-ML/Rank-Differential-Mechanism">Code</a>
        </span>
    </li>

      <li class="article">
        <span class="title">
          Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning
        </span>
        <span class="authors"><u>Rundong Luo</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
        <span class="journal-info">ICLR 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://openreview.net/pdf?id=0qmwFNJyxCL">PDF</a> |
          <a href="https://github.com/PKU-ML/DynACL">Code</a>
        </span>
    </li>

    <li class="article">
      <span class="title">
        ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond
      </span>
      <span class="authors"><u>Xiaojun Guo</u>*, <strong>Yifei Wang*</strong>, <u>Tianqi Du*</u>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=SM7XkJouWHm">PDF</a> | 
        <a href="https://github.com/PKU-ML/ContraNorm">Code</a>
      </span>
    </li>
  
        <li class="article">
          <span class="title">
          How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders
          </span>
          <span class="authors"><u>Qi Zhang</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
          <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span>   </span>
          <span class="year">2022</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2210.08344">PDF</a> |
            <a href="https://github.com/zhangq327/U-MAE">Code</a> |
            <a href="assets/slides/NeurIPS2022_mae.pdf">Slides</a>
          </span>
      </li>

        <li class="article">
          <span class="title">
          Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap <i class='no-italics' ></i>
          </span>
          <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
          <span class="journal-info">ICLR 2022</span>
          <span class="year">2022</span>
          <span class="links">
            <a href="http://arxiv.org/pdf/2203.13457">PDF</a> |
            <a href="https://github.com/zhangq327/ARC">Code</a> |
            <a href="assets/slides/ICLR2022_overlap.pdf">Slides</a>
          </span>
        </li>

      <li class="article">
        <span class="title">
          A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training <i class='no-italics'>  </i>
        </span>         
        <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
        <span class="journal-info">ICLR 2022 <span class="oral">(üèÜ Silver Best Paper Award @ ICML 2021 AdvML workshop)</span></span>
        <span class="year">2022</span>
        <span class="links">
          <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
          <a href="assets/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
        </span>
      </li>

      <li class="article">
        <span class="title">
        Residual Relaxation for Multi-view Representation Learning <i class='no-italics'></i>
        </span>
        <span class="authors"><strong>Yifei Wang</strong>, Zhengyang Geng, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
        <span class="journal-info">NeurIPS 2021</span>
        <span class="year">2021</span>
        <span class="links">
          <a href="https://arxiv.org/pdf/2110.15348">PDF</a> |
          <a href="assets/slides/NeurIPS2021_Prelax_slides.pdf">Slides</a> |
          <a href="https://mp.weixin.qq.com/s/AT9kWTNiImwS-Ns-zM5pCw">Blog </a>
        </span>
      </li>  

      <li class="article">
        <span class="title">
          Dissecting the Diffusion Process in Linear Graph Convolutional Networks <i class='no-italics'></i>
        </span>
        <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
        <span class="journal-info">NeurIPS 2021</span>
        <span class="year">2021</span>
        <span class="links">
          <a href="https://arxiv.org/pdf/2102.10739">PDF</a> |
          <a href="https://github.com/yifeiwang77/DGC">Code</a> |
          <a href="assets/slides/NeurIPS2021_DGC_slides.pdf">Slides</a> |
          <a href="https://mp.weixin.qq.com/s/H5GJnsc3F-qFAUPuZBJ4gA">Blog </a>
        </span>
        <!-- <span class="intro">A properly designed linear GCN (from a <strong>continuous</strong> perspective) is on par with SOTA nonlinear GCNs while being 100x faster => <strong>Unsupervised linear features</strong> can be astonishingly effective.</span> -->
      </li>  

      <li class="article">
        <span class="title">
        Reparameterized Sampling for Generative Adversarial Networks <i class='no-italics'> </i>
        </span>
                    
        <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
        <span class="journal-info"> ECML-PKDD 2021 
          </span>
        <span class="year">2021</span>
        <span class="oral">(üèÜ Best ML Paper Award (1/685). Invited to Machine Learning Journal)</span>              
        <span class="links">
          <a href="https://arxiv.org/pdf/2107.00352">PDF</a> |
          <a href="https://github.com/yifeiwang77/repgan">Code</a> |
          <a href="assets/slides/ECML2021_REPGAN_slides.pdf">Slides</a> |
          <a href="https://mp.weixin.qq.com/s/Ah43Tqhn0CL2kLxhI_nieQ">Media </a> |
          <a href="https://www.bilibili.com/video/BV1sL4y167gj">Talk </a> |
          <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Award</a>
        </span>
        <!-- <span class="intro">Efficient high-dimensional MCMC by reparameterizing Markov transitions into the <strong>low-dimensional latent space </strong> through implicit models (GANs). </span> -->
      </li>
    </ul>

    </div>


    <div id="All" class="tabcontent">
      <ul class="publications">

        <li class="article">
          <span class="title">
            On the Generalization of Multi-modal Contrastive Learning 
          </span>
          <span class="authors">Qi Zhang*, <strong>Yifei Wang*</strong>, Yisen Wang </span>
          <span class="journal-info">ICML 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2306.04272">PDF</a> | 
            <a href="https://github.com/PKU-ML/CLIP-Help-SimCLR">Code</a>
          </span>
          </li>


          <li class="article">
            <span class="title">
              Rethinking Weak Supervision in Helping Contrastive Representation Learning
            </span>
            <span class="authors">Jingyi Cui*, Weiran Huang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
            <span class="journal-info">ICML 2023</span>
            <span class="year">2023</span>
            <span class="links">
              <a href="https://arxiv.org/pdf/2306.04160">PDF</a>
            </span>
          </li>

            <li class="article">
              <span class="title">
                CFA: Class-wise Calibrated Fair Adversarial Training
              </span>
              <span class="authors">Zeming Wei, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
              <span class="journal-info">CVPR 2023</span>
              <span class="year">2023</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2303.14460.pdf">PDF</a>
              </span>
        
        <li class="article">
          <span class="title">
            Equilibrium Image Denoising with Implicit Differentiation
          </span>
          <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Zhengyang Geng, Yisen Wang, Jiansheng Yang, and Zhouchen Lin</span>
          <span class="journal-info">IEEE Transactions on Image Processing (TIP)</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://zhouchenlin.github.io/Publications/2023-TIP-Denoising.pdf">PDF</a>
          </span>
      </li>

        <li class="article">
          <span class="title">
            A Message Passing Perspective on Learning Dynamics of Contrastive Learning
          </span>
          <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, <u>Tianqi Du</u>, Jiansheng Yang, Zhouchen Lin, Yisen Wang </span>
          <span class="journal-info">ICLR 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://openreview.net/pdf?id=VBTJqqWjxMv">PDF</a> |
            <a href="https://github.com/PKU-ML/Message-Passing-Contrastive-Learning">Code</a> |
            <a href="assets/slides/ICLR23_Message_Passing.pdf">Slides</a> |
            <a href="https://mp.weixin.qq.com/s/e18pZfee7ffwAHMUBZ_OEg">Blog</a>
          </span>
      </li>

      <li class="article">
        <span class="title">
          Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism
        </span>
        <span class="authors"><u>Zhijian Zhuo*</u>, <strong>Yifei Wang*</strong>, Jinwen Ma, Yisen Wang </span>
        <span class="journal-info">ICLR 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://openreview.net/pdf?id=cIbjyd2Vcy">PDF</a> | 
          <a href="https://github.com/PKU-ML/Rank-Differential-Mechanism">Code</a>
        </span>
    </li>

      <li class="article">
        <span class="title">
          Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning
        </span>
        <span class="authors"><u>Rundong Luo</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
        <span class="journal-info">ICLR 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://openreview.net/pdf?id=0qmwFNJyxCL">PDF</a> |
          <a href="https://github.com/PKU-ML/DynACL">Code</a>
        </span>
    </li>

    <li class="article">
      <span class="title">
        ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond
      </span>
      <span class="authors"><u>Xiaojun Guo</u>*, <strong>Yifei Wang*</strong>, <u>Tianqi Du*</u>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=SM7XkJouWHm">PDF</a> | 
        <a href="https://github.com/PKU-ML/ContraNorm">Code</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States
      </span>
      <span class="authors">Mingjie Li, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=j3cUWIMsFBN">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        What Contrastive Learning Learns Beyond Class-wise Features?
      </span>
      <span class="authors">Xingyuming Liu, <strong>Yifei Wang</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models (ME-FoMo)</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=T-NiH_wB1O">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        Rethinking the Necessity of Labels in Backdoor Defense 
      </span>
      <span class="authors">Zidi Xiong, Dongxian Wu, <strong>Yifei Wang</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine Learning (BANDS)</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=Noj1Fydegod">PDF</a>
      </span>
    </li>


      <li class="article">
        <span class="title">
          On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization
        </span>
        <span class="authors"><u>Shiji Xin</u>, <strong>Yifei Wang</strong>, Jingtong Su, Yisen Wang</span>
        <span class="journal-info">AAAI 2023 <span class="oral">(Oral)</span></span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://arxiv.org/pdf/2212.09082.pdf">PDF</a>
        </span>
    </li>
     <li class="article">
        <span class="title">
        How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders
        </span>
        <!-- <span class="oral">SPOTLIGHT</span>               -->
        <span class="authors"><u>Qi Zhang</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
        <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span>   </span>
        <span class="year">2022</span>
        <span class="links">
          <a href="https://arxiv.org/pdf/2210.08344">PDF</a> |
          <a href="https://github.com/zhangq327/U-MAE">Code</a> |
          <a href="assets/slides/NeurIPS2022_mae.pdf">Slides</a>
        </span>
    </li>
    <li class="article">
      <span class="title">
      Improving Out-of-distribution Robustness by Adversarial Training with Structured Priors <i class='no-italics'>  </i>
      </span>
      <span class="authors"><u>Qixun Wang</u>*, <strong>Yifei Wang*</strong>, Hong Zhu, Yisen Wang</span>
      <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2210.06807">PDF</a> |
        <a href="https://github.com/NOVAglow646/NIPS22-MAT-and-LDAT-for-OOD">Code</a> |
        <a href="assets/slides/NeurIPS2022_OOD.pdf">Slides</a>
      </span>
    </li>

    <li class="article">
    <span class="title">
      When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture  <i class='no-italics'>  </i>
      </span>
      <!-- <span class="oral">SPOTLIGHT</span>               -->
      <span class="authors"><u>Yichuan Mo</u>, Dongxian Wu, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
      <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2210.07540.pdf">PDF</a> |
        <a href="https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers">Code</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        Variational Energy-Based Models: A Probabilistic Framework for Contrastive Self-Supervised Learning <i class='no-italics'>  </i>
      </span>
      <span class="authors"><u>Tianqi Du</u>*, <strong>Yifei Wang*</strong>, Weiran Huang, Yisen Wang</span>
      <span class="journal-info">NeurIPS 2022 SSL Workshop
      </span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://sslneurips22.github.io/paper_pdfs/paper_64.pdf">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
      AggNCE: Asymptotically Identifiable Contrastive Learning <i class='no-italics'>  </i>
      </span>
      <span class="authors">Jingyi Cui*, Weiran Huang*, <strong>Yifei Wang</strong>, Yisen Wang</span>
      <span class="journal-info">NeurIPS 2022 SSL Workshop <span class="oral">(Oral)</span></span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://sslneurips22.github.io/paper_pdfs/paper_68.pdf">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        Efficient and Scalable Implicit Graph Neural Networks with Virtual Equilibrium
        <i class='no-italics' ></i>
      </span>
      <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jianlong Chang, Qi Tian, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">IEEE BigData 2022 <span class="oral">(Long Talk)</span>
      <span class="year">2022</span>
      <span class="links">
        <a href="">PDF</a>
      </span>
    </li>
    
    <li class="article">
      <span class="title">
        Optimization-Induced Graph Implicit Nonlinear Diffusion
        <i class='no-italics' ></i>
      </span>
      <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">ICML 2022</span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf">PDF</a> | 
        <a href="https://github.com/7qchen/GIND">Code</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        G<sup>2</sup>CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters
        <i class='no-italics' ></i>
      </span>
      <span class="authors">Mingjie Li, <u>Xiaojun Guo</u>, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
      <span class="journal-info">ICML 2022</span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf">PDF</a>
    </li>

    <li class="article">
      <span class="title">
      Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap <i class='no-italics' ></i>
      </span>
      <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">ICLR 2022</span>
      <span class="year">2022</span>
      <span class="links">
        <a href="http://arxiv.org/pdf/2203.13457">PDF</a> |
        <a href="https://github.com/zhangq327/ARC">Code</a> |
        <a href="assets/slides/ICLR2022_overlap.pdf">Slides</a>
      </span>
    </li>
    <li class="article">
      <span class="title">
        A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training <i class='no-italics'>  </i>
      </span>         
      <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">ICLR 2022 <span class="oral">(üèÜ Silver Best Paper Award @ ICML 2021 AdvML workshop)</span></span>
      <span class="year">2022</span>
      <span class="links">
        <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
        <a href="assets/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
      </span>
    </li>
    <!-- <li class="article">
      <span class="title">
        Fooling Adversarial Training with Inducing Noise
        <i class='no-italics'></i>
      </span>
      <span class="authors"> <u>Zhirui Wang</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
      <span class="journal-info">Tech report, Nov. 2021</span>
      <span class="year">2021</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2111.10130">PDF</a> 
      </span>
    </li> -->
      <li class="article">
      <span class="title">
      Residual Relaxation for Multi-view Representation Learning <i class='no-italics'></i>
      </span>
      <span class="authors"><strong>Yifei Wang</strong>, Zhengyang Geng, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">NeurIPS 2021</span>
      <span class="year">2021</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2110.15348">PDF</a> |
        <a href="assets/slides/NeurIPS2021_Prelax_slides.pdf">Slides</a> |
        <a href="https://mp.weixin.qq.com/s/AT9kWTNiImwS-Ns-zM5pCw">Blog </a>
      </span>
    </li>
    <li class="article">
      <span class="title">
        Dissecting the Diffusion Process in Linear Graph Convolutional Networks <i class='no-italics'></i>
      </span>
      <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">NeurIPS 2021</span>
      <span class="year">2021</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2102.10739">PDF</a> |
        <a href="https://github.com/yifeiwang77/DGC">Code</a> |
        <a href="assets/slides/NeurIPS2021_DGC_slides.pdf">Slides</a> |
        <a href="https://mp.weixin.qq.com/s/H5GJnsc3F-qFAUPuZBJ4gA">Blog </a>
      </span>
      <!-- <span class="intro">A properly designed linear GCN (from a <strong>continuous</strong> perspective) is on par with SOTA nonlinear GCNs while being 100x faster => <strong>Unsupervised linear features</strong> can be astonishingly effective.</span> -->
    </li>
    <li class="article">
      <span class="title">
      Reparameterized Sampling for Generative Adversarial Networks <i class='no-italics'> </i>
      </span>
                  
      <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info"> ECML-PKDD 2021 
        </span>
      <span class="year">2021</span>
      <span class="oral">(üèÜ Best ML Paper Award (1/685) & Invited to <strong>Machine Learning</strong> Journal)</span>              
      <span class="links">
        <a href="https://arxiv.org/pdf/2107.00352">PDF</a> |
        <a href="https://github.com/yifeiwang77/repgan">Code</a> |
        <a href="assets/slides/ECML2021_REPGAN_slides.pdf">Slides</a> |
        <a href="https://mp.weixin.qq.com/s/Ah43Tqhn0CL2kLxhI_nieQ">Media </a> |
        <a href="https://www.bilibili.com/video/BV1sL4y167gj">Talk </a> |
        <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Award</a>
      </span>
      <!-- <span class="intro">Efficient high-dimensional MCMC by reparameterizing Markov transitions into the <strong>low-dimensional latent space </strong> through implicit models (GANs). </span> -->
    </li>
    <li class="article">
      <span class="title">
      Train Once, and Decode as You Like <i class='no-italics'></i>
      </span>
      <span class="authors">Chao Tian, <strong>Yifei Wang</strong>, Hao Cheng, Yijiang Lian, Zhihua Zhang</span>
      <span class="journal-info">COLING 2020</span>
      <span class="year">2020</span>
      <span class="links">
        <a href="https://www.aclweb.org/anthology/2020.coling-main.25.pdf">PDF</a> 
      </span>
      <!-- <span class="intro">Train an autoregressive language model with random ordering masks, and you can decode with whatever order (forward or backward) & whatever decoding steps <strong> (full-, semi-, or non- autoregressive). </span> -->
    </li>
    <!-- <li class="article">
      <span class="title">
        Decoder-free Robustness Disentanglement without (Additional) Supervision
        <i class='no-italics'></i>
      </span>
      <span class="authors"><strong>Yifei Wang</strong>, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang</span>
      <span class="journal-info">Tech report, July 2020</span>
      <span class="year">2020</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2007.01356">PDF</a> 
      </span>
       <span class="intro">Train an autoregressive language model with random ordering masks, and you can decode with whatever order (forward or backward) & whatever decoding steps <strong> (full-, semi-, or non- autoregressive). </span> 
    </li> -->
  </ul>
</div>

<div id="Unsupervised" class="tabcontent">
  <ul class="publications">

    <li class="article">
      <span class="title">
        On the Generalization of Multi-modal Contrastive Learning 
      </span>
      <span class="authors">Qi Zhang*, <strong>Yifei Wang*</strong>, Yisen Wang </span>
      <span class="journal-info">ICML 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2306.04272">PDF</a> | 
        <a href="https://github.com/PKU-ML/CLIP-Help-SimCLR">Code</a>
      </span>
      </li>


      <li class="article">
        <span class="title">
          Rethinking Weak Supervision in Helping Contrastive Representation Learning
        </span>
        <span class="authors">Jingyi Cui*, Weiran Huang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
        <span class="journal-info">ICML 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://arxiv.org/pdf/2306.04160">PDF</a>
        </span>
      </li>
    
      <li class="article">
        <span class="title">
          A Message Passing Perspective on Learning Dynamics of Contrastive Learning
        </span>
        <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, <u>Tianqi Du</u>, Jiansheng Yang, Zhouchen Lin, Yisen Wang </span>
        <span class="journal-info">ICLR 2023</span>
        <span class="year">2023</span>
        <span class="links">
          <a href="https://openreview.net/pdf?id=VBTJqqWjxMv">PDF</a> |
          <a href="https://github.com/PKU-ML/Message-Passing-Contrastive-Learning">Code</a> |
          <a href="assets/slides/ICLR23_Message_Passing.pdf">Slides</a> |
          <a href="https://mp.weixin.qq.com/s/e18pZfee7ffwAHMUBZ_OEg">Blog</a>          
        </span>
    </li>

    <li class="article">
      <span class="title">
        Towards a Unified Theoretical Understanding of Non-contrastive Learning via Rank Differential Mechanism
      </span>
      <span class="authors"><u>Zhijian Zhuo*</u>, <strong>Yifei Wang*</strong>, Jinwen Ma, Yisen Wang </span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=cIbjyd2Vcy">PDF</a> | 
        <a href="https://github.com/PKU-ML/Rank-Differential-Mechanism">Code</a>
      </span>
  </li>

    <li class="article">
      <span class="title">
        Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning
      </span>
      <span class="authors"><u>Rundong Luo</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=0qmwFNJyxCL">PDF</a> |
        <a href="https://github.com/PKU-ML/DynACL">Code</a>
      </span>
  </li>

  <li class="article">
    <span class="title">
      ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond
    </span>
    <span class="authors"><u>Xiaojun Guo</u>*, <strong>Yifei Wang*</strong>, <u>Tianqi Du*</u>, Yisen Wang</span>
    <span class="journal-info">ICLR 2023</span>
    <span class="year">2023</span>
    <span class="links">
      <a href="https://openreview.net/pdf?id=SM7XkJouWHm">PDF</a> | 
      <a href="https://github.com/PKU-ML/ContraNorm">Code</a>
    </span>
  </li>

      <li class="article">
      <span class="title">
        What Contrastive Learning Learns Beyond Class-wise Features?
      </span>
      <span class="authors">Xingyuming Liu, <strong>Yifei Wang</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023 Workshop on Mathematical and Empirical Understanding of Foundation Models (ME-FoMo)</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=T-NiH_wB1O">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
        Rethinking the Necessity of Labels in Backdoor Defense 
      </span>
      <span class="authors">Zidi Xiong, Dongxian Wu, <strong>Yifei Wang</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine Learning (BANDS)</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=Noj1Fydegod">PDF</a>
      </span>
    </li>

    <li class="article">
      <span class="title">
      How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders
      </span>
      <span class="authors"><u>Qi Zhang</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
      <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span>   </span>
      <span class="year">2022</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2210.08344">PDF</a> |
        <a href="https://github.com/zhangq327/U-MAE">Code</a> |
        <a href="assets/slides/NeurIPS2022_mae.pdf">Slides</a>
      </span>
  </li>

  <li class="article">
    <span class="title">
      Variational Energy-Based Models: A Probabilistic Framework for Contrastive Self-Supervised Learning <i class='no-italics'>  </i>
    </span>
    <span class="authors"><u>Tianqi Du</u>*, <strong>Yifei Wang*</strong>, Weiran Huang, Yisen Wang</span>
    <span class="journal-info">NeurIPS 2022 SSL Workshop
    </span>
    <span class="year">2022</span>
    <span class="links">
      <a href="https://sslneurips22.github.io/paper_pdfs/paper_64.pdf">PDF</a>
    </span>
  </li>

  <li class="article">
    <span class="title">
    AggNCE: Asymptotically Identifiable Contrastive Learning <i class='no-italics'>  </i>
    </span>
    <span class="authors">Jingyi Cui*, Weiran Huang*, <strong>Yifei Wang</strong>, Yisen Wang</span>
    <span class="journal-info">NeurIPS 2022 SSL Workshop <span class="oral">(Oral)</span></span>
    <span class="year">2022</span>
    <span class="links">
      <a href="https://sslneurips22.github.io/paper_pdfs/paper_68.pdf">PDF</a>
    </span>
  </li>

    <li class="article">
      <span class="title">
      Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap <i class='no-italics' ></i>
      </span>
      <span class="authors"><strong>Yifei Wang*</strong>, <u>Qi Zhang</u>*, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
      <span class="journal-info">ICLR 2022</span>
      <span class="year">2022</span>
      <span class="links">
        <a href="http://arxiv.org/pdf/2203.13457">PDF</a> |
        <a href="https://github.com/zhangq327/ARC">Code</a> |
        <a href="assets/slides/ICLR2022_overlap.pdf">Slides</a>
      </span>
    </li>

  <li class="article">
    <span class="title">
      A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training <i class='no-italics'>  </i>
    </span>         
    <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
    <span class="journal-info">ICLR 2022 <span class="oral">(üèÜ Silver Best Paper Award @ ICML 2021 AdvML workshop)</span></span>
    <span class="year">2022</span>
    <span class="links">
      <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
      <a href="assets/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
    </span>
  </li>

  <li class="article">
    <span class="title">
    Residual Relaxation for Multi-view Representation Learning <i class='no-italics'></i>
    </span>
    <span class="authors"><strong>Yifei Wang</strong>, Zhengyang Geng, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
    <span class="journal-info">NeurIPS 2021</span>
    <span class="year">2021</span>
    <span class="links">
      <a href="https://arxiv.org/pdf/2110.15348">PDF</a> |
      <a href="assets/slides/NeurIPS2021_Prelax_slides.pdf">Slides</a> |
      <a href="https://mp.weixin.qq.com/s/AT9kWTNiImwS-Ns-zM5pCw">Blog </a>
    </span>
  </li>

  <li class="article">
    <span class="title">
    Reparameterized Sampling for Generative Adversarial Networks <i class='no-italics'> </i>
    </span>
                
    <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
    <span class="journal-info"> ECML-PKDD 2021 
      </span>
    <span class="year">2021</span>
    <span class="oral">(üèÜ Best ML Paper Award (1/685). Invited to Machine Learning Journal)</span>              
    <span class="links">
      <a href="https://arxiv.org/pdf/2107.00352">PDF</a> |
      <a href="https://github.com/yifeiwang77/repgan">Code</a> |
      <a href="assets/slides/ECML2021_REPGAN_slides.pdf">Slides</a> |
      <a href="https://mp.weixin.qq.com/s/Ah43Tqhn0CL2kLxhI_nieQ">Media </a> |
      <a href="https://www.bilibili.com/video/BV1sL4y167gj">Talk </a> |
      <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Award</a>
    </span>
  </li>
</ul>
</div>


<div id="Adversarial" class="tabcontent">  
  <ul class="publications">
    <li class="article">
      <span class="title">
        CFA: Class-wise Calibrated Fair Adversarial Training
      </span>
      <span class="authors">Zeming Wei, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
      <span class="journal-info">CVPR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2303.14460.pdf">PDF</a>
      </span>
  
    <li class="article">
      <span class="title">
        Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning
      </span>
      <span class="authors"><u>Rundong Luo</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
      <span class="journal-info">ICLR 2023</span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://openreview.net/pdf?id=0qmwFNJyxCL">PDF</a>
      </span>
  </li>        

  <li class="article">
    <span class="title">
      Rethinking the Necessity of Labels in Backdoor Defense 
    </span>
    <span class="authors">Zidi Xiong, Dongxian Wu, <strong>Yifei Wang</strong>, Yisen Wang</span>
    <span class="journal-info">ICLR 2023 Workshop on Backdoor Attacks and Defenses in Machine Learning (BANDS)</span>
    <span class="year">2023</span>
    <span class="links">
      <a href="https://openreview.net/pdf?id=Noj1Fydegod">PDF</a>
    </span>
  </li>

    <li class="article">
      <span class="title">
        On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization
      </span>
      <span class="authors"><u>Shiji Xin</u>, <strong>Yifei Wang</strong>, Jingtong Su, Yisen Wang</span>
      <span class="journal-info">AAAI 2023 <span class="oral">(Oral)</span></span>
      <span class="year">2023</span>
      <span class="links">
        <a href="https://arxiv.org/pdf/2212.09082.pdf">PDF</a>
      </span>
  </li>
  <li class="article">
    <span class="title">
    Improving Out-of-distribution Robustness by Adversarial Training with Structured Priors <i class='no-italics'>  </i>
    </span>
    <span class="authors"><u>Qixun Wang</u>*, <strong>Yifei Wang*</strong>, Hong Zhu, Yisen Wang</span>
    <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
    <span class="year">2022</span>
    <span class="links">
      <a href="https://arxiv.org/pdf/2210.06807">PDF</a> |
      <a href="https://github.com/NOVAglow646/NIPS22-MAT-and-LDAT-for-OOD">Code</a> |
      <a href="assets/slides/NeurIPS2022_OOD.pdf">Slides</a>
    </span>
  </li>

  <li class="article">
  <span class="title">
    When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture  <i class='no-italics'>  </i>
    </span>
    <!-- <span class="oral">SPOTLIGHT</span>               -->
    <span class="authors"><u>Yichuan Mo</u>, Dongxian Wu, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
    <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
    <span class="year">2022</span>
    <span class="links">
      <a href="https://arxiv.org/pdf/2210.07540.pdf">PDF</a> |
      <a href="https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers">Code</a>
    </span>
  </li>
  <li class="article">
    <span class="title">
      A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training <i class='no-italics'>  </i>
    </span>         
    <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
    <span class="journal-info">ICLR 2022 <span class="oral">(üèÜ Silver Best Paper Award @ ICML 2021 AdvML workshop)</span></span>
    <span class="year">2022</span>
    <span class="links">
      <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
      <a href="assets/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
    </span>
  </li>
  <!-- <li class="article">
    <span class="title">
      Fooling Adversarial Training with Inducing Noise
      <i class='no-italics'></i>
    </span>
    <span class="authors"> <u>Zhirui Wang</u>*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
    <span class="journal-info">Tech report, Nov. 2021</span>
    <span class="year">2021</span>
    <span class="links">
      <a href="https://arxiv.org/pdf/2111.10130">PDF</a> 
    </span>
  </li> -->
  <!-- <li class="article">
    <span class="title">
      Decoder-free Robustness Disentanglement without (Additional) Supervision
      <i class='no-italics'></i>
    </span>
    <span class="authors"><strong>Yifei Wang</strong>, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang</span>
    <span class="journal-info">Tech report, July 2020</span>
    <span class="year">2020</span>
    <span class="links">
      <a href="https://arxiv.org/pdf/2007.01356">PDF</a> 
    </span>
  </li> -->
  </ul>
    </div>
    <div id="Graph" class="tabcontent">      
      <ul class="publications">
        <li class="article">
          <span class="title">
            ContraNorm: A Contrastive Learning Perspective on Oversmoothing and Beyond
          </span>
          <span class="authors"><u>Xiaojun Guo</u>*, <strong>Yifei Wang*</strong>, <u>Tianqi Du*</u>, Yisen Wang</span>
          <span class="journal-info">ICLR 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://openreview.net/pdf?id=SM7XkJouWHm">PDF</a>
          </span>
        </li>
    
        <li class="article">
          <span class="title">
            Unbiased Stochastic Proximal Solver for Graph Neural Networks with Equilibrium States
          </span>
          <span class="authors">Mingjie Li, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
          <span class="journal-info">ICLR 2023</span>
          <span class="year">2023</span>
          <span class="links">
            <a href="https://openreview.net/pdf?id=j3cUWIMsFBN">PDF</a>
          </span>
        </li>
    
        <li class="article">
          <span class="title">
            Efficient and Scalable Implicit Graph Neural Networks with Virtual Equilibrium
            <i class='no-italics' ></i>
          </span>
          <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jianlong Chang, Qi Tian, Jiansheng Yang, Zhouchen Lin</span>
          <span class="journal-info">IEEE BigData 2022 <span class="oral">(Long Talk)</span>
          <span class="year">2022</span>
          <span class="links">
            <a href="">PDF</a>
          </span>
        </li>

        <li class="article">
          <span class="title">
            Optimization-Induced Graph Implicit Nonlinear Diffusion
            <i class='no-italics' ></i>
          </span>
          <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
          <span class="journal-info">ICML 2022</span>
          <span class="year">2022</span>
          <span class="links">
            <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf">PDF</a> | 
            <a href="https://github.com/7qchen/GIND">Code</a>
          </span>
        </li>
      
        <li class="article">
          <span class="title">
            G<sup>2</sup>CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters
            <i class='no-italics' ></i>
          </span>
          <span class="authors">Mingjie Li, <u>Xiaojun Guo</u>, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
          <span class="journal-info">ICML 2022</span>
          <span class="year">2022</span>
          <span class="links">
            <a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf">PDF</a>
        </li>
        <li class="article">
          <span class="title">
            Dissecting the Diffusion Process in Linear Graph Convolutional Networks <i class='no-italics'></i>
          </span>
          <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
          <span class="journal-info">NeurIPS 2021</span>
          <span class="year">2021</span>
          <span class="links">
            <a href="https://arxiv.org/pdf/2102.10739">PDF</a> |
            <a href="https://github.com/yifeiwang77/DGC">Code</a> |
            <a href="assets/slides/NeurIPS2021_DGC_slides.pdf">Slides</a> |
            <a href="https://mp.weixin.qq.com/s/H5GJnsc3F-qFAUPuZBJ4gA">Blog </a>
          </span>
        </li>
      </ul>
        </div>
      </div>
    <div class="wrapper">
      <article class="post">
        <header class="post-header">
        <h1 class="post-title">Selected Awards</h1>
        </header>
        <div class="post-content">
          <strong>Beijing Excellent Graduate Award</strong>, 2023<br>
          <strong>Excellent Graduate Award</strong>, Peking University, 2023<br>
          <strong>National Scholarship</strong>, 2021, 2022 <br>
          <strong>Principal Scholarship</strong>, Peking University, 2022 <br>
          <strong><a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Best ML Paper Award</a></strong> (1/685), ECML-PKDD, 2021 <br>
          <!-- <a href="https://advml-workshop.github.io/icml2021/" style="color:#000000;"> -->
            <strong><a href="https://advml-workshop.github.io/icml2021/">Silver Best Paper Award</a></strong>, ICML AdvML workshop, 2021<br>
          <!-- <strong>Academic Innovation Award</strong>, Peking University, 2022. <br>   -->
          <!-- <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html" style="color:#000000;"> -->
      </div>
    </div>

    <div class="wrapper">
      <article class="post">
        <header class="post-header">
        <h1 class="post-title">Professional Services</h1>
        </header>
        <div class="post-content">
        I mainly review for machine learning conferences and journals, including ICLR, NeurIPS, ICML, TPAMI, LoG, ECML-PKDD. A part-time reviewer for computer vision (CVPR, ICCV) and natural language processing (ACL, EMNLP) conferences. 
        <!-- Reviewed for NeurIPS, ICLR, ICML, TPAMI (ML), CVPR, ICCV, ACL, EMNLP, ECML-PKDD. -->
      </div>
    </div>

  <!-- <div class="wrapper">
    <article class="post">
      <header class="post-header">
      <h1 class="post-title">Teaching</h1>
      </header>
      <div class="post-content">
      2022 Spring, TA in <strong>Advances in Machine Learning</strong>, instructed by Prof. Yisen Wang. <br>
      2021 Spring, TA in <strong>Trustworthy Machine Learning</strong>, instructed by Prof. Yisen Wang. <br>
      2018 Spring, TA in <strong>Optimization in Machine Learning</strong>, instructed by Prof. Zhouchen Lin. <br>
      2017 Fall, TA in <strong>Machine Learning</strong>, instructed by Prof. Tong Lin. <br>
    </div>
  </div>
</main> -->

<script>
  // Check if API exists
  if (document && document.fonts) {    
    // Do not block page loading
    setTimeout(function () {           
      document.fonts.load('16px "Mukta"').then(() => {
        // Make font using elements visible
        document.documentElement.classList.add('font-loaded') 
      })
    }, 0)
  } else {
    // Fallback if API does not exist 
    document.documentElement.classList.add('font-loaded') 
  }
</script>

<script>
  function openCity(evt, cityName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
      tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
      tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(cityName).style.display = "block";
    evt.currentTarget.className += " active";
  }
// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
  </script>

  </footer>
