<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" href="files/favicon.ico" type="image/x-icon">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Yifei Wang (PKU)</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="main.css">
  <link rel="canonical" href="yifeiwang.github.io">

  <link rel="stylesheet" href="main.css">
  <link rel="canonical" href="yifeiwang.github.io">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Mukta:wght@300;400&display=swap" rel="stylesheet">

  <!-- <style>
    a { color: #FF0000; } /* CSS link color */
  </style> -->
</head>

<body data-new-gr-c-s-check-loaded="14.1029.0" data-gr-ext-installed="">

    <div class="wrapper">
        <article class="post">
            <header class="post-header">
              <h1 class="post-title">Selected Publications Listed by Topic</h1>
            </header>
            <ul class="publications">
            <!-- <strong>Preprints</strong> <br><br> -->
            <!-- <div class="post-content">
                <li class="article">
                    <span class="title">
                      Fooling Adversarial Training with Inducing Noise <i class='no-italics'></i>
                    </span>
                    <span class="authors">Zhirui Wang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
                    <span class="journal-info">arXiv preprint arXiv:2111.10130</span>
                    <span class="year">2021</span>
                    <span class="links">
                      <a href="https://arxiv.org/pdf/2111.10130">PDF</a>
                    </span>
                    <!-- <span class="intro">Adversarial training is NOT the cure to data poisoning and it can also be fooled. The key is to inject an inducing noise that misleads the models to the hell.</span>                   </li>
             -->
                  <!-- <li class="article">
                    <span class="title">
                    Decoder-free Robustness Disentanglement without (Additional) Supervision <i class='no-italics'></i>
                    </span>
                    <span class="authors"><strong>Yifei Wang</strong>, Peng Dan, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang</span>
                    <span class="journal-info">arXiv preprint arXiv:2007.01356	 </span>
                    <span class="year">2020</span>
                    <span class="links">
                      <a href="https://arxiv.org/pdf/2007.01356">PDF</a> 
                    </span>
                    <!-- <span class="intro"> Disentangling and preserving both robust and sensitive (non-robust) features in an end-to-end fashion. </span>
                  </li>   -->
            <!-- <strong>Peer Reviewed</strong> <br><br> -->

          üéÇ Self-supervised Learning<br><br>
          <li class="article">
              <span class="title">
              Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning <br> via Augmentation Overlap <i class='no-italics' ></i>
              </span>
              <span class="authors"><strong>Yifei Wang*</strong>, Qi Zhang*, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">ICLR 2022</span>
              <span class="year">2022</span>
              <span class="links">
                <a href="http://arxiv.org/pdf/2203.13457">PDF</a> |
                <a href="https://github.com/zhangq327/ARC">Code</a> |
                <a href="files/slides/ICLR2022_overlap.pdf">Slides</a>
              </span>
            </li>
            <ul class="publications">
              <li class="article">
                <span class="title">
                How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders
                </span>
                <span class="authors">Qi Zhang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
                <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span>   </span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="https://arxiv.org/pdf/2210.08344">PDF</a> |
                  <a href="https://github.com/zhangq327/U-MAE">Code</a>
                </span>
            </li>
    
              <li class="article">
              <span class="title">
              Residual Relaxation for Multi-view Representation Learning <i class='no-italics'></i>
              </span>
              <span class="authors"><strong>Yifei Wang</strong>, Zhengyang Geng, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">NeurIPS 2021</span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2110.15348">PDF</a> |
                <a href="files/slides/NeurIPS2021_Prelax_slides.pdf">Slides</a> |
                <a href="https://mp.weixin.qq.com/s/AT9kWTNiImwS-Ns-zM5pCw">Blog </a>
              </span>
              <!-- <span class="intro" hidden="hidden">Do we really need exact alignment of different views in contrastive learning? We show this could be 1) problematic and 2) resolved through a residual relaxation mechanism.</span> -->
            </li>
            <!-- <strong></strong>üé≤ Self-supervised Generative Modeling<br><br> -->
            <li class="article">
              <span class="title">
                A Unified Contrastive Energy-based Model for Understanding the Generative Ability  <br> of Adversarial Training <i class='no-italics'>  </i>
              </span>
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">ICLR 2022 <span class="oral">(üèÜ Silver Best Paper Award @ ICML 2021 AML workshop)</span></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
                <a href="files/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
              </span>
            </li>
            <li class="article">
              <span class="title">
                Variational Energy-Based Models: A Probabilistic Framework for Contrastive Self-Supervised Learning <i class='no-italics'>  </i>
              </span>
              <span class="authors">Tianqi Du*, <strong>Yifei Wang*</strong>, Weiran Huang, Yisen Wang</span>
              <span class="journal-info">NeurIPS 2022 SSL Workshop
              </span>
              <span class="year">2022</span>
              <span class="links">
                <a href="https://sslneurips22.github.io/paper_pdfs/paper_64.pdf">PDF</a>
              </span>
            </li>

            <li class="article">
              <span class="title">
              AggNCE: Asymptotically Identifiable Contrastive Learning <i class='no-italics'>  </i>
              </span>
              <span class="authors">Jingyi Cui*, Weiran Huang*, <strong>Yifei Wang</strong>, Yisen Wang</span>
              <span class="journal-info">NeurIPS 2022 SSL Workshop <span class="oral">(Oral)</span></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="https://sslneurips22.github.io/paper_pdfs/paper_68.pdf">PDF</a>
              </span>
            </li>
            <li class="article">
              <span class="title">
              Reparameterized Sampling for Generative Adversarial Networks <i class='no-italics'> </i>
              </span>
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info"> ECML-PKDD 2021 
              </span>
            <span class="year">2021</span>
            <span class="oral">(üèÜ Best ML Paper Award (1/685) & Invited to <strong>Machine Learning</strong> Journal)</span>              
            <span class="links">
                <a href="https://arxiv.org/pdf/2107.00352">PDF</a> |
                <a href="https://github.com/yifeiwang77/repgan">Code</a> |
                <a href="files/slides/ECML2021_REPGAN_slides.pdf">Slides</a> |
                <a href="https://mp.weixin.qq.com/s/Ah43Tqhn0CL2kLxhI_nieQ">Media </a> |
                <a href="https://www.bilibili.com/video/BV1sL4y167gj">Talk </a> |
                <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Award</a>
              </span>
              <!-- <span class="intro">Efficient high-dimensional MCMC by reparameterizing Markov transitions into the <strong>low-dimensional latent space </strong> through implicit models (GANs). </span> -->
            </li>

            <!-- <li class="article">
              <span class="title">
              Demystifying Adversarial Training via A Unified Probabilistic Framework <i class='no-italics'>  </i>
              </span>
              <span class="oral">(Silver Best Paper Award)</span>
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">AML Workshop of International Conference on Machine Learning <strong>(ICML-W 2021)</strong></span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://openreview.net/pdf?id=U0TCTe68s41">PDF</a> |
                <!-- <a href="files/posters/ICML_w2021_CEM_poster.pdf">Poster</a> | -->
                <!-- <a href="https://mp.weixin.qq.com/s/E99rIA0lZ6aFeAlYe2Znrw">Blog </a> |
                <a href="https://advml-workshop.github.io/icml2021/">Award</a> | 
                <a href="http://arxiv.org/pdf/2203.13455">Update: conference version @ ICLR 2022</a>
              </span>
              <!-- <span class="intro">Adversarial training implicitly learns a contrastive energy-based model.</span>               -->
            <!-- </li>             -->
            
            üî® Robust Representation Learning<br><br>
            <li class="article">
              <span class="title">
              Improving Out-of-distribution Robustness by Adversarial Training with Structured Priors <i class='no-italics'>  </i>
              </span>
              <span class="authors">Qixun Wang*, <strong>Yifei Wang*</strong>, Hong Zhu, Yisen Wang</span>
              <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2210.06807">PDF</a> |
                <a href="https://github.com/NOVAglow646/NIPS22-MAT-and-LDAT-for-OOD">Code</a>
              </span>
            </li>


            <ul class="publications">
              <li class="article">
                <span class="title">
                  On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization
                </span>
                <!-- <span class="oral">SPOTLIGHT</span>               -->
                <span class="authors">Shiji Xin, <strong>Yifei Wang</strong>, Jingtong Su, Yisen Wang</span>
                <span class="journal-info">AAAI 2023</span>
                <span class="year">2023</span>
                <span class="links">
                  <a href="">PDF</a>
                </span>
            </li>

            <li class="article">
              <span class="title">
                When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture  <i class='no-italics'>  </i>
                </span>
                <span class="authors">Yichuan Mo, Dongxian Wu, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
                <span class="journal-info">NeurIPS 2022 <span class="oral">(Spotlight, Top 5%)</span></span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="https://arxiv.org/pdf/2210.07540.pdf">PDF</a> |
                  <a href="https://github.com/mo666666/When-Adversarial-Training-Meets-Vision-Transformers">Code</a>
                </span>
              </li>

              üîó Graph Representation Learning<br><br>
              <li class="article">
                <span class="title">
                  Dissecting the Diffusion Process in Linear Graph Convolutional Networks <i class='no-italics'></i>
                </span>
                <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
                <span class="journal-info">NeurIPS 2021</span>
                <span class="year">2021</span>
                <span class="links">
                  <a href="https://arxiv.org/pdf/2102.10739">PDF</a> |
                  <a href="https://github.com/yifeiwang77/DGC">Code</a> |
                  <a href="files/slides/NeurIPS2021_DGC_slides.pdf">Slides</a> |
                  <a href="https://mp.weixin.qq.com/s/H5GJnsc3F-qFAUPuZBJ4gA">Blog </a>
                </span>
                <!-- <span class="intro">A properly designed linear GCN (from a <strong>continuous</strong> perspective) is on par with SOTA nonlinear GCNs while being 100x faster => <strong>Unsupervised linear features</strong> can be astonishingly effective.</span> -->
              </li>
              <li class="article">
                <span class="title">
                  Optimization-Induced Graph Implicit Nonlinear Diffusion
                  <i class='no-italics' ></i>
                </span>
                <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
                <span class="journal-info">ICML 2022</span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf">PDF</a> | 
                  <a href="https://github.com/7qchen/GIND">Code</a>
                </span>
              </li>
  
              <li class="article">
                <span class="title">
                  G<sup>2</sup>CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters
                  <i class='no-italics' ></i>
                </span>
                <span class="authors">Mingjie Li, Xiaojun Guo, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
                <span class="journal-info">ICML 2022</span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf">PDF</a>
              </li>              
          </ul>
        </div>
        <!-- <span class="footnote">* denotes equal contribution, often meaning multiple authors contributed to coding and running experiments.</span> -->
      </article>
    </div>