<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="icon" href="files/favicon.ico" type="image/x-icon">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Yifei Wang (PKU)</title>
  <meta name="description" content="">

  <link rel="stylesheet" href="main.css">
  <link rel="canonical" href="yifeiwang.github.io">

  <!-- <style>
    a { color: #FF0000; } /* CSS link color */
  </style> -->
</head>

<body data-new-gr-c-s-check-loaded="14.1029.0" data-gr-ext-installed="">

    <div class="wrapper">
        <article class="post">
            <header class="post-header">
              <h1 class="post-title">Publication</h1>
            </header>
            <ul class="publications">
            <strong>Preprints</strong> <br><br>
            <div class="post-content">
                <li class="article">
                    <span class="title">
                      Fooling Adversarial Training with Inducing Noise <i class='no-italics'></i>
                    </span>
                    <span class="authors">Zhirui Wang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
                    <span class="journal-info">arXiv preprint arXiv:2111.10130</span>
                    <span class="year">2021</span>
                    <span class="links">
                      <a href="https://arxiv.org/pdf/2111.10130">PDF</a>
                    </span>
                    <!-- <span class="intro">Adversarial training is NOT the cure to data poisoning and it can also be fooled. The key is to inject an inducing noise that misleads the models to the hell.</span> -->
                  </li>
            
                  <li class="article">
                    <span class="title">
                    Decoder-free Robustness Disentanglement without (Additional) Supervision <i class='no-italics'></i>
                    </span>
                    <span class="authors"><strong>Yifei Wang</strong>, Peng Dan, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng Yang</span>
                    <span class="journal-info">arXiv preprint arXiv:2007.01356	 </span>
                    <span class="year">2020</span>
                    <span class="links">
                      <a href="https://arxiv.org/pdf/2007.01356">PDF</a> 
                    </span>
                    <!-- <span class="intro"> Disentangling and preserving both robust and sensitive (non-robust) features in an end-to-end fashion. </span> -->
                  </li>  
            <strong>Peer Reviewed</strong> <br><br>

          üéÇ Self-supervised Representation Learning<br><br>
          <li class="article">
            <span class="title">
            How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders
            </span>
            <span class="authors">Qi Zhang*, <strong>Yifei Wang*</strong>, Yisen Wang</span>
            <span class="journal-info">Advances in Neural Information Processing Systems <strong>(NeurIPS 2022)</strong></span>
            <span class="year">2022</span>
            <span class="links">
              <a href="">PDF</a>
            </span>
          </li>


          <li class="article">
              <span class="title">
              Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning <br> via Augmentation Overlap <i class='no-italics' ></i>
              </span>
              <span class="authors"><strong>Yifei Wang*</strong>, Qi Zhang*, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">International Conference on Learning Representations <strong>(ICLR 2022)</strong></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="http://arxiv.org/pdf/2203.13457">PDF</a> |
                <a href="https://github.com/zhangq327/ARC">Code</a> |
                <a href="files/slides/ICLR2022_overlap.pdf">Slides</a>
              </span>
            </li>

              <li class="article">
              <span class="title">
              Residual Relaxation for Multi-view Representation Learning <i class='no-italics'></i>
              </span>
              <span class="authors"><strong>Yifei Wang</strong>, Zhengyang Geng, Feng Jiang, Chuming Li, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">Advances in Neural Information Processing Systems <strong>(NeurIPS 2021)</strong></span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2110.15348">PDF</a> |
                <a href="files/slides/NeurIPS2021_Prelax_slides.pdf">Slides</a> |
                <a href="https://mp.weixin.qq.com/s/AT9kWTNiImwS-Ns-zM5pCw">Blog </a>
              </span>
              <!-- <span class="intro" hidden="hidden">Do we really need exact alignment of different views in contrastive learning? We show this could be 1) problematic and 2) resolved through a residual relaxation mechanism.</span> -->
            </li>
            <strong></strong>üé≤ Self-supervised Generative Modeling<br><br>
            <li class="article">
              <span class="title">
                A Unified Contrastive Energy-based Model for Understanding the Generative Ability  <br> of Adversarial Training <i class='no-italics'>  </i>
              </span>
              <span class="oral">üèÜ Silver Best Paper Award @ ICML 2021 AML workshop</span>              
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">International Conference on Learning Representations <strong>(ICLR 2022)</strong></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
                <a href="files/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
              </span>
            </li>

            <li class="article">
              <span class="title">
              Reparameterized Sampling for Generative Adversarial Networks <i class='no-italics'> </i>
              </span>
              <span class="oral">üèÜ Best Machine Learning Paper Award </span>              
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">European Conference on Machine Learning <strong>(ECML-PKDD 2021)</strong>
                </span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2107.00352">PDF</a> |
                <a href="https://github.com/yifeiwang77/repgan">Code</a> |
                <a href="files/slides/ECML2021_REPGAN_slides.pdf">Slides</a> |
                <a href="https://mp.weixin.qq.com/s/Ah43Tqhn0CL2kLxhI_nieQ">Media </a> |
                <a href="https://www.bilibili.com/video/BV1sL4y167gj">Talk </a> |
                <a href="https://2021.ecmlpkdd.org/index.html@p=2148.html">Award</a>
              </span>
              <!-- <span class="intro">Efficient high-dimensional MCMC by reparameterizing Markov transitions into the <strong>low-dimensional latent space </strong> through implicit models (GANs). </span> -->
            </li>

            <!-- <li class="article">
              <span class="title">
              Demystifying Adversarial Training via A Unified Probabilistic Framework <i class='no-italics'>  </i>
              </span>
              <span class="oral">(Silver Best Paper Award)</span>
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">AML Workshop of International Conference on Machine Learning <strong>(ICML-W 2021)</strong></span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://openreview.net/pdf?id=U0TCTe68s41">PDF</a> |
                <!-- <a href="files/posters/ICML_w2021_CEM_poster.pdf">Poster</a> | -->
                <!-- <a href="https://mp.weixin.qq.com/s/E99rIA0lZ6aFeAlYe2Znrw">Blog </a> |
                <a href="https://advml-workshop.github.io/icml2021/">Award</a> | 
                <a href="http://arxiv.org/pdf/2203.13455">Update: conference version @ ICLR 2022</a>
              </span>
              <!-- <span class="intro">Adversarial training implicitly learns a contrastive energy-based model.</span>               -->
            <!-- </li>             -->
            
            <li class="article">
              <span class="title">
              Train Once, and Decode as You Like <i class='no-italics'></i>
              </span>
              <span class="authors">Chao Tian, <strong>Yifei Wang</strong>, Hao Cheng, Yijiang Lian, Zhihua Zhang</span>
              <span class="journal-info">International Committee on Computational Linguistics <strong>(COLING 2020)</strong> </span>
              <span class="year">2020</span>
              <span class="links">
                <a href="https://www.aclweb.org/anthology/2020.coling-main.25.pdf">PDF</a> 
              </span>
              <!-- <span class="intro">Train an autoregressive language model with random ordering masks, and you can decode with whatever order (forward or backward) & whatever decoding steps <strong> (full-, semi-, or non- autoregressive)</strong>. </span> -->
            </li>
            üîó Geometric Representation Learning<br><br>
            <li class="article">
              <span class="title">
                Dissecting the Diffusion Process in Linear Graph Convolutional Networks <i class='no-italics'></i>
              </span>
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">Advances in Neural Information Processing Systems <strong>(NeurIPS 2021)</strong></span>
              <span class="year">2021</span>
              <span class="links">
                <a href="https://arxiv.org/pdf/2102.10739">PDF</a> |
                <a href="https://github.com/yifeiwang77/DGC">Code</a> |
                <a href="files/slides/NeurIPS2021_DGC_slides.pdf">Slides</a> |
                <a href="https://mp.weixin.qq.com/s/H5GJnsc3F-qFAUPuZBJ4gA">Blog </a>
              </span>
              <!-- <span class="intro">A properly designed linear GCN (from a <strong>continuous</strong> perspective) is on par with SOTA nonlinear GCNs while being 100x faster => <strong>Unsupervised linear features</strong> can be astonishingly effective.</span> -->
            </li>
            <li class="article">
              <span class="title">
                Optimization-Induced Graph Implicit Nonlinear Diffusion
                <i class='no-italics' ></i>
              </span>
              <span class="authors">Qi Chen, <strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">International Conference on Machine Learning <strong>(ICML 2022)</strong></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf">PDF</a> | 
                <a href="https://github.com/7qchen/GIND">Code</a>
              </span>
            </li>

            <li class="article">
              <span class="title">
                G<sup>2</sup>CN: Graph Gaussian Convolution Networks with Concentrated Graph Filters
                <i class='no-italics' ></i>
              </span>
              <span class="authors">Mingjie Li, Xiaojun Guo, <strong>Yifei Wang</strong>, Yisen Wang, Zhouchen Lin</span>
              <span class="journal-info">International Conference on Machine Learning <strong>(ICML 2022)</strong></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="https://proceedings.mlr.press/v162/li22h/li22h.pdf">PDF</a>
            </li>
            üî® Robust Representation Learning<br><br>
            <li class="article">
                <span class="title">
                Improving Out-of-distribution Robustness by Adversarial Training with Structured Priors <i class='no-italics'>  </i>
                </span>
                <span class="authors">Qixun Wang*, <strong>Yifei Wang*</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
                <span class="journal-info">Advances in Neural Information Processing Systems <strong>(NeurIPS 2022)</strong></span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="">PDF</a>
                </span>
              </li>

              <li class="article">
              <span class="title">
                When Adversarial Training Meets Vision Transformers: Recipes from Training to Architecture  <i class='no-italics'>  </i>
                </span>
                <span class="authors">Yichuan Mo, Dongxian Wu, <strong>Yifei Wang</strong>, Yiwen Guo, Yisen Wang</span>
                <span class="journal-info">Advances in Neural Information Processing Systems <strong>(NeurIPS 2022)</strong></span>
                <span class="year">2022</span>
                <span class="links">
                  <a href="">PDF</a>
                </span>
              </li>
              
            <li class="article">
              <span class="title">
                A Unified Contrastive Energy-based Model for Understanding the Generative Ability  <br> of Adversarial Training <i class='no-italics'>  </i>
              </span>
              <span class="oral">üèÜ Silver Best Paper Award @ ICML 2021 AML workshop</span>              
              <span class="authors"><strong>Yifei Wang</strong>, Yisen Wang, Jiansheng Yang, Zhouchen Lin</span>
              <span class="journal-info">International Conference on Learning Representations <strong>(ICLR 2022)</strong></span>
              <span class="year">2022</span>
              <span class="links">
                <a href="http://arxiv.org/pdf/2203.13455">PDF</a> |
                <a href="files/slides/ICLR2022_CEM.pdf">Slides</a> | <a href="https://advml-workshop.github.io/icml2021/">Award</a> 
              </span>
            </li>
          </ul>
        </div>
        <!-- <span class="footnote">* denotes equal contribution, often meaning multiple authors contributed to coding and running experiments.</span> -->
      </article>
    </div>